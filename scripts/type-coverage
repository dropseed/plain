#!/usr/bin/env python3
"""
Type annotation coverage calculator for Python codebases.

Analyzes Python files to determine the percentage of functions/methods
that have complete type annotations (parameters and return types).
"""

import argparse
import ast
import os
import sys
from dataclasses import dataclass, field
from fnmatch import fnmatch
from pathlib import Path
from typing import List, Optional


@dataclass
class FunctionInfo:
    """Information about a function/method for type checking."""
    name: str
    file: str
    line: int
    is_method: bool = False
    has_return_type: bool = False
    total_params: int = 0
    typed_params: int = 0
    is_property: bool = False

    @property
    def is_fully_typed(self) -> bool:
        """Check if function has all type annotations."""
        return self.has_return_type and (self.typed_params == self.total_params)


@dataclass
class FileStats:
    """Statistics for a single Python file."""
    path: str
    functions: List[FunctionInfo] = field(default_factory=list)

    @property
    def total_functions(self) -> int:
        return len(self.functions)

    @property
    def fully_typed_functions(self) -> int:
        return sum(1 for f in self.functions if f.is_fully_typed)

    @property
    def coverage_percentage(self) -> float:
        if not self.functions:
            return 100.0
        return (self.fully_typed_functions / self.total_functions) * 100


class TypeCoverageAnalyzer(ast.NodeVisitor):
    """AST visitor to analyze type annotations in Python code."""

    def __init__(self, file_path: str):
        self.file_path = file_path
        self.functions: List[FunctionInfo] = []
        self.class_stack: List[str] = []

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        """Track when we enter/exit a class."""
        self.class_stack.append(node.name)
        self.generic_visit(node)
        self.class_stack.pop()

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        """Analyze function definitions."""
        self._analyze_function(node)
        self.generic_visit(node)

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> None:
        """Analyze async function definitions."""
        self._analyze_function(node)
        self.generic_visit(node)

    def _analyze_function(self, node: ast.FunctionDef | ast.AsyncFunctionDef) -> None:
        """Analyze a function/method for type annotations."""
        # Skip __init__ return type check (it's always None implicitly)
        is_init = node.name == "__init__"

        # Check if it's a method (inside a class)
        is_method = bool(self.class_stack)

        # Check decorators
        is_property = any(
            (isinstance(d, ast.Name) and d.id == "property") or
            (isinstance(d, ast.Attribute) and d.attr == "property")
            for d in node.decorator_list
        )

        # Create function info
        func_info = FunctionInfo(
            name=node.name,
            file=self.file_path,
            line=node.lineno,
            is_method=is_method,
            is_property=is_property,
        )

        # Check return type (not needed for __init__)
        if not is_init:
            func_info.has_return_type = node.returns is not None
        else:
            func_info.has_return_type = True

        def handle_param(arg: ast.arg) -> None:
            if is_method and arg.arg in {"self", "cls"}:
                return

            func_info.total_params += 1
            if arg.annotation is not None:
                func_info.typed_params += 1

        # Analyze parameters
        for arg in node.args.posonlyargs:
            handle_param(arg)

        for arg in node.args.args:
            handle_param(arg)

        for arg in node.args.kwonlyargs:
            handle_param(arg)

        # Check *args and **kwargs
        if node.args.vararg:
            func_info.total_params += 1
            if node.args.vararg.annotation is not None:
                func_info.typed_params += 1

        if node.args.kwarg:
            func_info.total_params += 1
            if node.args.kwarg.annotation is not None:
                func_info.typed_params += 1

        self.functions.append(func_info)


def analyze_file(file_path: Path) -> Optional[FileStats]:
    """Analyze a single Python file for type coverage."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        tree = ast.parse(content, filename=str(file_path))
        analyzer = TypeCoverageAnalyzer(str(file_path))
        analyzer.visit(tree)

        stats = FileStats(path=str(file_path), functions=analyzer.functions)
        return stats

    except (SyntaxError, UnicodeDecodeError) as e:
        print(f"Warning: Could not parse {file_path}: {e}", file=sys.stderr)
        return None


def find_python_files(directory: Path, exclude_patterns: Optional[List[str]] = None) -> List[Path]:
    """Find all Python files in a directory, excluding certain patterns."""
    default_patterns = [
        "__pycache__",
        ".git",
        ".venv",
        "venv",
        "env",
        ".tox",
        "build",
        "dist",
        "*.egg-info",
        ".mypy_cache",
        ".pytest_cache",
    ]

    patterns = list(default_patterns)
    if exclude_patterns:
        patterns.extend(exclude_patterns)

    def should_exclude(path: Path) -> bool:
        try:
            relative = path.relative_to(directory).as_posix()
        except ValueError:
            relative = path.as_posix()

        candidates = {relative, path.as_posix(), path.name}
        for pattern in patterns:
            if any(fnmatch(candidate, pattern) for candidate in candidates):
                return True
        return False

    python_files = []

    for root, dirs, files in os.walk(directory):
        # Filter out excluded directories
        root_path = Path(root)
        dirs[:] = [
            d for d in dirs
            if not should_exclude(root_path / d)
        ]

        for file in files:
            if file.endswith('.py'):
                file_path = root_path / file
                # Check if file path matches excluded patterns
                if not should_exclude(file_path):
                    python_files.append(file_path)

    return python_files


def format_report(
    all_stats: List[FileStats],
    show_details: bool = False,
    show_missing: bool = False,
    min_coverage: Optional[float] = None
) -> str:
    """Format the coverage report."""
    lines = []

    # Calculate overall statistics
    total_functions = sum(s.total_functions for s in all_stats)
    fully_typed_functions = sum(s.fully_typed_functions for s in all_stats)

    if total_functions > 0:
        overall_coverage = (fully_typed_functions / total_functions) * 100
    else:
        overall_coverage = 100.0

    # Summary
    lines.append(f"Overall Coverage: {overall_coverage:.1f}%")
    lines.append(f"Functions analyzed: {total_functions}")
    lines.append(f"Fully typed functions: {fully_typed_functions}")
    lines.append(f"Missing annotations: {total_functions - fully_typed_functions}")
    lines.append("")

    if show_details:
        lines.append("-" * 80)
        lines.append("FILE BREAKDOWN")
        lines.append("-" * 80)

        # Sort files by coverage (lowest first)
        sorted_stats = sorted(all_stats, key=lambda s: s.coverage_percentage)

        for stats in sorted_stats:
            if stats.total_functions == 0:
                continue

            # Skip files with good coverage if min_coverage is set
            if min_coverage is not None and stats.coverage_percentage >= min_coverage:
                continue

            lines.append(f"\n{stats.path}")
            lines.append(f"  Coverage: {stats.coverage_percentage:.1f}% ({stats.fully_typed_functions}/{stats.total_functions})")

            if show_missing:
                missing_functions = [f for f in stats.functions if not f.is_fully_typed]
                if missing_functions:
                    lines.append("  Missing annotations:")
                    for func in missing_functions[:10]:  # Limit to first 10
                        issues = []
                        if not func.has_return_type:
                            issues.append("return")
                        missing_params = func.total_params - func.typed_params
                        if missing_params > 0:
                            issues.append(f"{missing_params} param(s)")

                        lines.append(f"    - {func.name}:{func.line} [{', '.join(issues)}]")

                    if len(missing_functions) > 10:
                        lines.append(f"    ... and {len(missing_functions) - 10} more")

    # Coverage distribution
    lines.append("")
    lines.append("-" * 80)
    lines.append("COVERAGE DISTRIBUTION")
    lines.append("-" * 80)

    ranges = [
        (100, 100, "Perfect (100%)"),
        (90, 99, "Excellent (90-99%)"),
        (75, 89, "Good (75-89%)"),
        (50, 74, "Fair (50-74%)"),
        (25, 49, "Poor (25-49%)"),
        (0, 24, "Very Poor (0-24%)"),
    ]

    for min_pct, max_pct, label in ranges:
        count = sum(1 for s in all_stats
                   if s.total_functions > 0 and min_pct <= s.coverage_percentage <= max_pct)
        if count > 0:
            lines.append(f"  {label}: {count} file(s)")

    return "\n".join(lines)


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Calculate type annotation coverage for Python code"
    )
    parser.add_argument(
        "directory",
        type=str,
        help="Directory to analyze"
    )
    parser.add_argument(
        "--details",
        action="store_true",
        help="Show detailed breakdown by file"
    )
    parser.add_argument(
        "--missing",
        action="store_true",
        help="Show which functions are missing annotations"
    )
    parser.add_argument(
        "--min-coverage",
        type=float,
        metavar="PERCENT",
        help="Only show files below this coverage percentage"
    )
    parser.add_argument(
        "--exclude",
        type=str,
        action="append",
        help="Additional patterns to exclude (can be used multiple times)"
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Output results as JSON"
    )
    parser.add_argument(
        "--fail-under",
        type=float,
        metavar="PERCENT",
        help="Exit with error code if coverage is below this percentage"
    )

    args = parser.parse_args()

    # Validate directory
    directory = Path(args.directory)
    if not directory.exists():
        print(f"Error: Directory '{directory}' does not exist", file=sys.stderr)
        sys.exit(1)

    if not directory.is_dir():
        print(f"Error: '{directory}' is not a directory", file=sys.stderr)
        sys.exit(1)

    # Find Python files
    exclude_patterns = args.exclude if args.exclude else None
    python_files = find_python_files(directory, exclude_patterns)

    if not python_files:
        print(f"No Python files found in '{directory}'", file=sys.stderr)
        sys.exit(1)

    print(f"Analyzing {len(python_files)} Python files...", file=sys.stderr)

    # Analyze files
    all_stats = []
    for file_path in python_files:
        stats = analyze_file(file_path)
        if stats:
            all_stats.append(stats)

    # Output results
    if args.json:
        import json

        # Calculate overall statistics
        total_functions = sum(s.total_functions for s in all_stats)
        fully_typed_functions = sum(s.fully_typed_functions for s in all_stats)
        overall_coverage = (fully_typed_functions / total_functions * 100) if total_functions > 0 else 100.0

        result = {
            "overall_coverage": overall_coverage,
            "total_functions": total_functions,
            "fully_typed_functions": fully_typed_functions,
            "files": [
                {
                    "path": s.path,
                    "coverage": s.coverage_percentage,
                    "total_functions": s.total_functions,
                    "fully_typed_functions": s.fully_typed_functions,
                    "functions": [
                        {
                            "name": f.name,
                            "line": f.line,
                            "is_fully_typed": f.is_fully_typed,
                            "has_return_type": f.has_return_type,
                            "typed_params": f.typed_params,
                            "total_params": f.total_params,
                        }
                        for f in s.functions
                    ] if args.missing else []
                }
                for s in all_stats
                if s.total_functions > 0
            ]
        }
        print(json.dumps(result, indent=2))
    else:
        report = format_report(
            all_stats,
            show_details=args.details,
            show_missing=args.missing,
            min_coverage=args.min_coverage
        )
        print(report)

    # Check fail-under threshold
    if args.fail_under:
        total_functions = sum(s.total_functions for s in all_stats)
        fully_typed_functions = sum(s.fully_typed_functions for s in all_stats)
        overall_coverage = (fully_typed_functions / total_functions * 100) if total_functions > 0 else 100.0

        if overall_coverage < args.fail_under:
            print(f"\nError: Coverage {overall_coverage:.1f}% is below threshold {args.fail_under}%", file=sys.stderr)
            sys.exit(1)


if __name__ == "__main__":
    main()
